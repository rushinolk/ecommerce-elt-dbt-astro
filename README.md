# Olist Data Pipeline: Engenharia de Dados com dbt, Airflow (Cosmos) e AWS

## üìñ Sobre o Projeto
Este projeto simula um ambiente real de Engenharia de Dados utilizando o dataset p√∫blico de e-commerce brasileiro (Olist). O objetivo principal n√£o foi apenas movimentar dados, mas construir um pipeline robusto focado em **Qualidade de Dados (Data Quality)** e **Governan√ßa**.

O pipeline consome dados brutos (CSV), trata inconsist√™ncias reais (nulos, duplicatas, erros de tipagem) e entrega dados confi√°veis e testados em um Data Warehouse na nuvem, utilizando o **dbt** integrado ao **Airflow** via **Astronomer Cosmos**.

---

## üèóÔ∏è Arquitetura (Medallion)

O projeto segue a arquitetura de camadas para garantir organiza√ß√£o, rastreabilidade e performance:

1.  **Bronze (Raw):** Ingest√£o dos arquivos CSV originais, convertidos para formato otimizado e carregados no **AWS RDS (PostgreSQL)**.
2.  **Silver (Trusted):**
    * Limpeza e padroniza√ß√£o de nomes de colunas.
    * **Tipagem Forte:** Convers√£o de strings para `TIMESTAMP`, `NUMERIC` e `INT` via SQL `CAST`.
    * **Regras de Neg√≥cio:** Cria√ß√£o de colunas calculadas como `dias_ate_aprovacao` e `tempo_entrega_real`.
    * **Tratamento de Nulos:** Aplica√ß√£o de regras de *fallback* (ex: `COALESCE`) para dados incompletos.
3.  **Gold (Analytics):**
    * **Modelagem Dimensional:** Cria√ß√£o de tabelas Fato e Dimens√µes prontas para BI.
    * **Deduplica√ß√£o:** Unifica√ß√£o de cadastros de clientes para garantir vis√£o √∫nica.

---

## üõ†Ô∏è Tech Stack

* **Linguagem:** Python 3.9+ & SQL
* **Transforma√ß√£o & Testes:** dbt Core (Data Build Tool)
* **Orquestra√ß√£o:** Apache Airflow (via Astronomer Cosmos)
* **Banco de Dados:** AWS RDS (PostgreSQL)
* **Infraestrutura:** Docker & Docker Compose

---

## ‚ú® Destaques T√©cnicos

### 1. Tratamento de Data Quality (Camada Silver)
Dados reais raramente v√™m limpos. Implementei estrat√©gias de saneamento diretamente no SQL:
* **Categorias Nulas:** Produtos sem categoria foram tratados via `COALESCE(category, 'outros')` para evitar "buracos" nas an√°lises de BI.
* **Datas:** Convers√£o expl√≠cita de texto para `TIMESTAMP` para permitir c√°lculos precisos de SLA log√≠stico.

### 2. Testes Automatizados de Integridade (dbt Tests)
Para garantir a confiabilidade do Data Warehouse, configurei testes autom√°ticos no `schema.yml` que rodam a cada execu√ß√£o do pipeline:
* **`not_null`:** Garante que chaves prim√°rias e IDs vitais nunca sejam nulos.
* **`relationships`:** Assegura a integridade referencial entre a Tabela Fato (Pedidos) e as Dimens√µes (Clientes, Produtos), impedindo que um pedido referencie um cliente inexistente.

### 3. Deduplica√ß√£o de Clientes (SCD Type 1)
Um desafio comum no dataset do Olist √© a duplicidade de clientes. Utilizei *Window Functions* para aplicar a l√≥gica de manter apenas o registro mais recente:

```sql
/* Exemplo da l√≥gica de deduplica√ß√£o */
ROW_NUMBER() OVER(
    PARTITION BY customer_unique_id 
    ORDER BY customer_id DESC
) as rn
... WHERE rn = 1

### 4. Orquestra√ß√£o como C√≥digo (Cosmos)
Utilizei o **Astronomer Cosmos** para integrar o dbt ao Airflow. Isso permite que o Airflow renderize automaticamente cada modelo dbt como uma Task individual no grafo (DAG), respeitando as depend√™ncias definidas nas `refs` do SQL.

---

## üöÄ Como Executar Localmente

### Pr√©-requisitos
* Docker e Astro CLI instalados.
* Git instalado.

### Passo a Passo

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/rushinolk/ecommerce-elt-dbt-astro.git](https://github.com/rushinolk/ecommerce-elt-dbt-astro.git)
    cd olist-data-pipeline
    ```

2.  **Configure as Vari√°veis de Ambiente:**
    Crie um arquivo `.env` na raiz do projeto com as credenciais do banco de dados (exemplo):
    ```env
    POSTGRES_USER=postgres
    POSTGRES_PASSWORD=sua_senha
    POSTGRES_HOST=seu_endpoint_rds_ou_local
    POSTGRES_DB=olist
    ```

3.  **Suba o Ambiente:**
    ```bash
    docker-compose up -d
    ```

4.  **Acesse o Airflow:**
    Abra `http://localhost:8080` no navegador (login/senha padr√£o: `admin`/`admin`). Ative a DAG `olist_dbt_dag` para iniciar o processamento.

---

## üìä Pr√≥ximos Passos
* [ ] Constru√ß√£o de Dashboard no Power BI conectado √† camada Gold.
* [ ] Implementa√ß√£o de alertas autom√°ticos (Slack/Email) em caso de falha nos testes do dbt.
* [ ] CI/CD para deploy autom√°tico dos modelos dbt.

---

### üì¨ Contato
Gostou do projeto? Vamos conectar!
* [LinkedIn](https://www.linkedin.com/in/arthur-gomes1/)
